{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "\n",
    "TEMPLATE = {\n",
    "    \"dataset_name_or_path\": \"\",\n",
    "    \"model_name_or_path\": \"\",\n",
    "    \"load_half_precision\": False,\n",
    "    \"pooler\": \"\",\n",
    "    \"batch_size\": -1,\n",
    "    \"max_length\": -1,\n",
    "    \"prompt_path\": \"\",\n",
    "    \"output_dir\": \"\"\n",
    "}\n",
    "\n",
    "PROMPT_MAP = {\n",
    "    \"Mistral_7B_Instruct\": \"mistral_prompt.txt\",\n",
    "    \"Llama3_8B_Instruct\": \"llama3_prompt.txt\",\n",
    "    \"Llama2_7B\": \"llama2_prompt.txt\",\n",
    "    \"Llama2_7B_Chat\": \"llama2_prompt.txt\",\n",
    "    \"Gemma_7B_Instruct\": \"gemma_prompt.txt\",\n",
    "}\n",
    "\n",
    "MODEL_MAP = {\n",
    "    \"Mistral_7B_Instruct\": \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    \"Llama3_8B_Instruct\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    \"Llama2_7B\": \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"Llama2_7B_Chat\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    \"Gemma_7B_Instruct\": \"google/gemma-7b-it\"\n",
    "}\n",
    "\n",
    "def make_config(\n",
    "    dataset_name: str,\n",
    "    model_name: str,\n",
    "    pooler: str, \n",
    "    batch_size: int,\n",
    "    max_length: str,\n",
    "    prompt_prefix: str = None,\n",
    "    output_dir: str = None,\n",
    "    output_fname: str = \"config\"\n",
    "):\n",
    "    config = copy.deepcopy(TEMPLATE)\n",
    "    config['dataset_name_or_path'] = dataset_name\n",
    "    config['model_name_or_path'] = MODEL_MAP[model_name] if model_name in MODEL_MAP else model_name\n",
    "    config['pooler'] = pooler\n",
    "    config['batch_size'] = batch_size\n",
    "    config['max_length'] = max_length\n",
    "    config['prompt_path'] = f\"{prompt_prefix}/{PROMPT_MAP[model_name]}\" if model_name in PROMPT_MAP else prompt_prefix\n",
    "    config['output_dir'] = output_dir if output_dir is not None else f\"./{dataset_name}/{model_name}/{pooler}\"\n",
    "    with open(f\"{output_fname}.json\", 'w') as file:\n",
    "        json.dump(config, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Toxigen\n",
    "\n",
    "DATASET = \"toxigen\"\n",
    "POOLER = \"mean_with_attention\"\n",
    "\n",
    "for model_name in MODEL_MAP:\n",
    "    make_config(\n",
    "        dataset_name=DATASET,\n",
    "        model_name=model_name,\n",
    "        pooler=POOLER, \n",
    "        batch_size=4,\n",
    "        max_length=512,\n",
    "        prompt_prefix=f\"{DATASET}/zero_shot\",\n",
    "        output_dir=None,\n",
    "        output_fname=f\"{DATASET}/{model_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ESNLI\n",
    "\n",
    "DATASET = \"esnli\"\n",
    "POOLER = \"mean_with_attention\"\n",
    "\n",
    "for model_name in MODEL_MAP:\n",
    "    make_config(\n",
    "        dataset_name=DATASET,\n",
    "        model_name=model_name,\n",
    "        pooler=POOLER, \n",
    "        batch_size=4,\n",
    "        max_length=512,\n",
    "        prompt_prefix=f\"{DATASET}/zero_shot\",\n",
    "        output_dir=None,\n",
    "        output_fname=f\"{DATASET}/{model_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ESNLI subset\n",
    "\n",
    "DATASET = \"esnli_subset\"\n",
    "POOLER = \"mean_with_attention\"\n",
    "\n",
    "for model_name in MODEL_MAP:\n",
    "    make_config(\n",
    "        dataset_name=DATASET,\n",
    "        model_name=model_name,\n",
    "        pooler=POOLER, \n",
    "        batch_size=4,\n",
    "        max_length=512,\n",
    "        prompt_prefix=f\"{DATASET}/zero_shot\",\n",
    "        output_dir=None,\n",
    "        output_fname=f\"{DATASET}/{model_name}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrapperbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
