{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# TODO: Think about plotting subset sizes against predicted probability? (confidence)\n",
    "\n",
    "DATASET_NAME = \"toxigen\"\n",
    "LABEL_SPACE = [\"non-toxic\", \"toxic\"]\n",
    "MODEL_NAME = \"deberta-large\"\n",
    "SEED = 42\n",
    "POOLER = \"mean_with_attention\"\n",
    "LAYER = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samsoup/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.1.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/samsoup/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.1.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/samsoup/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# load embeddings\n",
    "from data.embeddings import load_saved_embeddings\n",
    "import numpy as np\n",
    "train_embeddings = load_saved_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"train\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "eval_embeddings = load_saved_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"eval\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "test_embeddings = load_saved_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"test\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "train_eval_embeddings = np.vstack([train_embeddings, eval_embeddings])\n",
    "\n",
    "\n",
    "# load classifier\n",
    "from data.models import load_saved_wrapperbox_model\n",
    "knn_clf = load_saved_wrapperbox_model(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=\"KNN\"\n",
    ")\n",
    "\n",
    "svm_clf = load_saved_wrapperbox_model(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=\"SVM\",\n",
    ")\n",
    "\n",
    "dt_clf = load_saved_wrapperbox_model(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=\"DecisionTree\",\n",
    ")\n",
    "\n",
    "lmeans_clf = load_saved_wrapperbox_model(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=\"LMeans\",\n",
    ")\n",
    "\n",
    "# load labels \n",
    "from data.datasets import load_dataset_from_hf, load_labels_at_split\n",
    "dataset = load_dataset_from_hf(dataset=DATASET_NAME)\n",
    "train_labels = load_labels_at_split(dataset, \"train\")\n",
    "eval_labels = load_labels_at_split(dataset, \"eval\")\n",
    "train_eval_labels = np.concatenate([train_labels, eval_labels])\n",
    "test_labels = load_labels_at_split(dataset, \"test\")\n",
    "\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "train_eval_dataset = concatenate_datasets([dataset[\"train\"], dataset[\"eval\"]])\n",
    "dataset_dict = DatasetDict(\n",
    "    {\"train\": train_eval_dataset, \"test\": dataset[\"test\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_accuracy': 0.8202127659574469,\n",
      " 'test_f1': 0.6817325800376648,\n",
      " 'test_precision': 0.7327935222672065,\n",
      " 'test_recall': 0.6373239436619719}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       656\n",
      "           1       0.73      0.64      0.68       284\n",
      "\n",
      "    accuracy                           0.82       940\n",
      "   macro avg       0.79      0.77      0.78       940\n",
      "weighted avg       0.82      0.82      0.82       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.inference import compute_metrics\n",
    "\n",
    "l2 = 500\n",
    "logit_clf = LogisticRegression(penalty=\"l2\", C= 1 / l2)\n",
    "\n",
    "logit_clf.fit(train_eval_embeddings, train_eval_labels)\n",
    "\n",
    "predictions = logit_clf.predict(test_embeddings)\n",
    "\n",
    "# Print some metrics\n",
    "testset_perfm = compute_metrics(\n",
    "    y_true=test_labels, y_pred=predictions, is_multiclass=False, prefix=\"test\"\n",
    ")\n",
    "pprint(testset_perfm)\n",
    "print(classification_report(y_true=test_labels, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_accuracy': 0.8223404255319149,\n",
      " 'test_f1': 0.7023172905525846,\n",
      " 'test_precision': 0.7111913357400722,\n",
      " 'test_recall': 0.6936619718309859}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87       656\n",
      "           1       0.71      0.69      0.70       284\n",
      "\n",
      "    accuracy                           0.82       940\n",
      "   macro avg       0.79      0.79      0.79       940\n",
      "weighted avg       0.82      0.82      0.82       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from classifiers.KMeansClassifier import KMeansClassifier\n",
    "clf = KMeansClassifier(\n",
    "    n_clusters=2, init='k-means++', random_state=42, algorithm='elkan'\n",
    ")\n",
    "clf.fit(train_eval_embeddings, train_eval_labels)\n",
    "predictions = clf.predict(test_embeddings)\n",
    "\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.inference import compute_metrics\n",
    "\n",
    "# Print some metrics\n",
    "testset_perfm = compute_metrics(\n",
    "    y_true=test_labels, y_pred=predictions, is_multiclass=False, prefix=\"test\"\n",
    ")\n",
    "pprint(testset_perfm)\n",
    "print(classification_report(y_true=test_labels, y_pred=predictions))\n",
    "\n",
    "import pickle\n",
    "# Save model to file\n",
    "model_filename = 'LMeans.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrapperbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
