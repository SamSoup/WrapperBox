{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1298/1298 [00:59<00:00, 21.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 identified subsets are valid\n",
      "Overall validity is 97/1298, or 7.47%\n",
      "Precision validity is 97/97, or 100.0%\n",
      "Identified 97/1298 subsets.\n",
      "Coverage: 7.47%\n",
      "Median Valid Subset Sizes is 24.0, out of 97 valid subsets\n",
      "{'Coverage': 7.47,\n",
      " 'Median Size': 24.0,\n",
      " 'Overall Validity': 7.47,\n",
      " 'Precision Validity': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate essays, yang fast\n",
    "\n",
    "from utils.constants.directory import SAVED_MODELS_DIR, EMBEDDINGS_DIR, DATASETS_DIR\n",
    "from utils.io import load_pickle\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"essays\"\n",
    "\n",
    "## Load Embeddings\n",
    "embeddings_path = os.path.join(EMBEDDINGS_DIR, DATASET_NAME)\n",
    "train_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"train.npy\")\n",
    ").squeeze()\n",
    "\n",
    "test_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"test.npy\")\n",
    ").squeeze()\n",
    "\n",
    "## Load labels\n",
    "dir = os.path.join(DATASETS_DIR, DATASET_NAME)\n",
    "train_data = pd.read_csv(os.path.join(dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(dir, \"test.csv\"))\n",
    "\n",
    "train_labels = np.array(train_data[\"label\"])\n",
    "test_labels = np.array(test_data[\"label\"])\n",
    "\n",
    "## Load Model\n",
    "model_path = SAVED_MODELS_DIR / DATASET_NAME / \"LogisticRegression.pkl\"\n",
    "model = load_pickle(model_path)\n",
    "    \n",
    "\n",
    "name = \"yang_fast\"\n",
    "filename = f\"results/{DATASET_NAME}/{DATASET_NAME}_{name}.pkl\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=model,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_embeddings,\n",
    "    train_labels=train_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=np.arange(len(test_labels))\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'results/{DATASET_NAME}/{name}_metrics.json'\n",
    "pickle_file_path = f'results/{DATASET_NAME}/{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1298/1298 [01:08<00:00, 18.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/97 identified subsets are valid\n",
      "Overall validity is 93/1298, or 7.16%\n",
      "Precision validity is 93/97, or 95.88%\n",
      "Identified 97/1298 subsets.\n",
      "Coverage: 7.47%\n",
      "Median Valid Subset Sizes is 12.0, out of 93 valid subsets\n",
      "{'Coverage': 7.47,\n",
      " 'Median Size': 12.0,\n",
      " 'Overall Validity': 7.16,\n",
      " 'Precision Validity': 95.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate essays, yang fast\n",
    "\n",
    "from utils.constants.directory import SAVED_MODELS_DIR, EMBEDDINGS_DIR, DATASETS_DIR\n",
    "from utils.io import load_pickle\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"essays\"\n",
    "\n",
    "## Load Embeddings\n",
    "embeddings_path = os.path.join(EMBEDDINGS_DIR, DATASET_NAME)\n",
    "train_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"train.npy\")\n",
    ").squeeze()\n",
    "\n",
    "test_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"test.npy\")\n",
    ").squeeze()\n",
    "\n",
    "## Load labels\n",
    "dir = os.path.join(DATASETS_DIR, DATASET_NAME)\n",
    "train_data = pd.read_csv(os.path.join(dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(dir, \"test.csv\"))\n",
    "\n",
    "train_labels = np.array(train_data[\"label\"])\n",
    "test_labels = np.array(test_data[\"label\"])\n",
    "\n",
    "## Load Model\n",
    "model_path = SAVED_MODELS_DIR / DATASET_NAME / \"LogisticRegression.pkl\"\n",
    "model = load_pickle(model_path)\n",
    "    \n",
    "\n",
    "name = \"yang_slow\"\n",
    "filename = f\"results/{DATASET_NAME}/{DATASET_NAME}_{name}.pkl\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=model,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_embeddings,\n",
    "    train_labels=train_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=np.arange(len(test_labels))\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'results/{DATASET_NAME}/{name}_metrics.json'\n",
    "pickle_file_path = f'results/{DATASET_NAME}/{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [14:40<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 identified subsets are valid\n",
      "Overall validity is 720/1003, or 71.78%\n",
      "Precision validity is 720/720, or 100.0%\n",
      "Identified 720/1003 subsets.\n",
      "Coverage: 71.78%\n",
      "Median Valid Subset Sizes is 64.0, out of 720 valid subsets\n",
      "{'Coverage': 71.78,\n",
      " 'Median Size': 64.0,\n",
      " 'Overall Validity': 71.78,\n",
      " 'Precision Validity': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate emotion, yang fast\n",
    "\n",
    "from utils.constants.directory import SAVED_MODELS_DIR, EMBEDDINGS_DIR, DATASETS_DIR\n",
    "from utils.io import load_pickle\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"emotion\"\n",
    "\n",
    "## Load Embeddings\n",
    "embeddings_path = os.path.join(EMBEDDINGS_DIR, DATASET_NAME)\n",
    "train_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"train.npy\")\n",
    ").squeeze()\n",
    "\n",
    "test_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"test.npy\")\n",
    ").squeeze()\n",
    "\n",
    "## Load labels\n",
    "dir = os.path.join(DATASETS_DIR, DATASET_NAME)\n",
    "train_data = pd.read_csv(os.path.join(dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(dir, \"test.csv\"))\n",
    "\n",
    "train_labels = np.array(train_data[\"label\"])\n",
    "test_labels = np.array(test_data[\"label\"])\n",
    "\n",
    "## Load Model\n",
    "model_path = SAVED_MODELS_DIR / DATASET_NAME / \"LogisticRegression.pkl\"\n",
    "model = load_pickle(model_path)\n",
    "    \n",
    "\n",
    "name = \"yang_fast\"\n",
    "filename = f\"results/{DATASET_NAME}/{DATASET_NAME}_{name}.pkl\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=model,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_embeddings,\n",
    "    train_labels=train_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=np.arange(len(test_labels))\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'results/{DATASET_NAME}/{name}_metrics.json'\n",
    "pickle_file_path = f'results/{DATASET_NAME}/{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [15:13<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/720 identified subsets are valid\n",
      "Overall validity is 710/1003, or 70.79%\n",
      "Precision validity is 710/720, or 98.61%\n",
      "Identified 720/1003 subsets.\n",
      "Coverage: 71.78%\n",
      "Median Valid Subset Sizes is 51.0, out of 710 valid subsets\n",
      "{'Coverage': 71.78,\n",
      " 'Median Size': 51.0,\n",
      " 'Overall Validity': 70.79,\n",
      " 'Precision Validity': 98.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate emotion, yang slow\n",
    "\n",
    "from utils.constants.directory import SAVED_MODELS_DIR, EMBEDDINGS_DIR, DATASETS_DIR\n",
    "from utils.io import load_pickle\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"emotion\"\n",
    "\n",
    "## Load Embeddings\n",
    "embeddings_path = os.path.join(EMBEDDINGS_DIR, DATASET_NAME)\n",
    "train_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"train.npy\")\n",
    ").squeeze()\n",
    "\n",
    "test_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"test.npy\")\n",
    ").squeeze()\n",
    "\n",
    "## Load labels\n",
    "dir = os.path.join(DATASETS_DIR, DATASET_NAME)\n",
    "train_data = pd.read_csv(os.path.join(dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(dir, \"test.csv\"))\n",
    "\n",
    "train_labels = np.array(train_data[\"label\"])\n",
    "test_labels = np.array(test_data[\"label\"])\n",
    "\n",
    "## Load Model\n",
    "model_path = SAVED_MODELS_DIR / DATASET_NAME / \"LogisticRegression.pkl\"\n",
    "model = load_pickle(model_path)\n",
    "    \n",
    "\n",
    "name = \"yang_slow\"\n",
    "filename = f\"results/{DATASET_NAME}/{DATASET_NAME}_{name}.pkl\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=model,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_embeddings,\n",
    "    train_labels=train_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=np.arange(len(test_labels))\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'results/{DATASET_NAME}/{name}_metrics.json'\n",
    "pickle_file_path = f'results/{DATASET_NAME}/{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1071/1071 [08:49<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/567 identified subsets are valid\n",
      "Overall validity is 371/1071, or 34.64%\n",
      "Precision validity is 371/567, or 65.43%\n",
      "Identified 567/1071 subsets.\n",
      "Coverage: 52.94%\n",
      "Median Valid Subset Sizes is 135.0, out of 371 valid subsets\n",
      "{'Coverage': 52.94,\n",
      " 'Median Size': 135.0,\n",
      " 'Overall Validity': 34.64,\n",
      " 'Precision Validity': 65.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate hatespeech, yang fast\n",
    "\n",
    "from utils.constants.directory import SAVED_MODELS_DIR, EMBEDDINGS_DIR, DATASETS_DIR\n",
    "from utils.io import load_pickle\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"hatespeech\"\n",
    "\n",
    "## Load Embeddings\n",
    "embeddings_path = os.path.join(EMBEDDINGS_DIR, DATASET_NAME)\n",
    "train_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"train.npy\")\n",
    ").squeeze()\n",
    "\n",
    "test_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"test.npy\")\n",
    ").squeeze()\n",
    "\n",
    "## Load labels\n",
    "dir = os.path.join(DATASETS_DIR, DATASET_NAME)\n",
    "train_data = pd.read_csv(os.path.join(dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(dir, \"test.csv\"))\n",
    "\n",
    "train_labels = np.array(train_data[\"label\"])\n",
    "test_labels = np.array(test_data[\"label\"])\n",
    "\n",
    "## Load Model\n",
    "model_path = SAVED_MODELS_DIR / DATASET_NAME / \"LogisticRegression.pkl\"\n",
    "model = load_pickle(model_path)\n",
    "    \n",
    "\n",
    "name = \"yang_fast\"\n",
    "filename = f\"results/{DATASET_NAME}/{DATASET_NAME}_{name}.pkl\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=model,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_embeddings,\n",
    "    train_labels=train_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=np.arange(len(test_labels))\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'results/{DATASET_NAME}/{name}_metrics.json'\n",
    "pickle_file_path = f'results/{DATASET_NAME}/{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 1071, 0.5266106442577031)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"hatespeech\"\n",
    "name = \"yang_fast\"\n",
    "thresh = 0.25\n",
    "\n",
    "new_fname = f\"./results/{dataset}/{dataset}_{name}_new_predictions.npy\"\n",
    "\n",
    "new_pred = np.load(new_fname, allow_pickle=True)\n",
    "\n",
    "old_fname = f\"./results/{dataset}/{dataset}_{name}_old_predictions.npy\"\n",
    "\n",
    "old_pred = np.load(old_fname, allow_pickle=True)\n",
    "\n",
    "true_old_pred = old_pred >= thresh\n",
    "\n",
    "is_valid_3 = []\n",
    "for po, pn in zip(true_old_pred, new_pred):\n",
    "    if pn is None:\n",
    "        is_valid_3.append(False)\n",
    "        continue\n",
    "    pr = pn >= thresh\n",
    "    # print(pr, po[0])\n",
    "    if pr != po[0]:\n",
    "        is_valid_3.append(True)\n",
    "    else:\n",
    "        is_valid_3.append(False)\n",
    "\n",
    "is_valid_3 = np.array(is_valid_3)\n",
    "\n",
    "sum(is_valid_3), is_valid_3.size, sum(is_valid_3)/is_valid_3.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1071/1071 [08:09<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/497 identified subsets are valid\n",
      "Overall validity is 341/1071, or 31.84%\n",
      "Precision validity is 341/497, or 68.61%\n",
      "Identified 497/1071 subsets.\n",
      "Coverage: 46.41%\n",
      "Median Valid Subset Sizes is 103.0, out of 341 valid subsets\n",
      "{'Coverage': 46.41,\n",
      " 'Median Size': 103.0,\n",
      " 'Overall Validity': 31.84,\n",
      " 'Precision Validity': 68.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate hatespeech, yang slow\n",
    "\n",
    "from utils.constants.directory import SAVED_MODELS_DIR, EMBEDDINGS_DIR, DATASETS_DIR\n",
    "from utils.io import load_pickle\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"hatespeech\"\n",
    "\n",
    "## Load Embeddings\n",
    "embeddings_path = os.path.join(EMBEDDINGS_DIR, DATASET_NAME)\n",
    "train_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"train.npy\")\n",
    ").squeeze()\n",
    "\n",
    "test_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"test.npy\")\n",
    ").squeeze()\n",
    "\n",
    "## Load labels\n",
    "dir = os.path.join(DATASETS_DIR, DATASET_NAME)\n",
    "train_data = pd.read_csv(os.path.join(dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(dir, \"test.csv\"))\n",
    "\n",
    "train_labels = np.array(train_data[\"label\"])\n",
    "test_labels = np.array(test_data[\"label\"])\n",
    "\n",
    "## Load Model\n",
    "model_path = SAVED_MODELS_DIR / DATASET_NAME / \"LogisticRegression.pkl\"\n",
    "model = load_pickle(model_path)\n",
    "    \n",
    "\n",
    "name = \"yang_slow\"\n",
    "filename = f\"results/{DATASET_NAME}/{DATASET_NAME}_{name}.pkl\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=model,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_embeddings,\n",
    "    train_labels=train_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=np.arange(len(test_labels))\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'results/{DATASET_NAME}/{name}_metrics.json'\n",
    "pickle_file_path = f'results/{DATASET_NAME}/{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 1071, 0.44164332399626516)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"hatespeech\"\n",
    "name = \"yang_slow\"\n",
    "thresh = 0.25\n",
    "\n",
    "new_fname = f\"./results/{dataset}/{dataset}_{name}_new_predictions.npy\"\n",
    "\n",
    "new_pred = np.load(new_fname, allow_pickle=True)\n",
    "\n",
    "old_fname = f\"./results/{dataset}/{dataset}_{name}_old_predictions.npy\"\n",
    "\n",
    "old_pred = np.load(old_fname, allow_pickle=True)\n",
    "\n",
    "true_old_pred = old_pred >= thresh\n",
    "\n",
    "is_valid_3 = []\n",
    "for po, pn in zip(true_old_pred, new_pred):\n",
    "    if pn is None:\n",
    "        is_valid_3.append(False)\n",
    "        continue\n",
    "    pr = pn >= thresh\n",
    "    # print(pr, po[0])\n",
    "    if pr != po[0]:\n",
    "        is_valid_3.append(True)\n",
    "    else:\n",
    "        is_valid_3.append(False)\n",
    "\n",
    "is_valid_3 = np.array(is_valid_3)\n",
    "\n",
    "coverage = sum()\n",
    "\n",
    "sum(is_valid_3), is_valid_3.size, sum(is_valid_3)/is_valid_3.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [35:52<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895/898 identified subsets are valid\n",
      "Overall validity is 895/1000, or 89.5%\n",
      "Precision validity is 895/898, or 99.67%\n",
      "Identified 898/1000 subsets.\n",
      "Coverage: 89.8%\n",
      "Median Valid Subset Sizes is 110.0, out of 895 valid subsets\n",
      "{'Coverage': 89.8,\n",
      " 'Median Size': 110.0,\n",
      " 'Overall Validity': 89.5,\n",
      " 'Precision Validity': 99.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate tweets, yang slow\n",
    "\n",
    "from utils.constants.directory import SAVED_MODELS_DIR, EMBEDDINGS_DIR, DATASETS_DIR\n",
    "from utils.io import load_pickle\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"tweets\"\n",
    "\n",
    "## Load Embeddings\n",
    "embeddings_path = os.path.join(EMBEDDINGS_DIR, DATASET_NAME)\n",
    "train_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"train.npy\")\n",
    ").squeeze()\n",
    "\n",
    "test_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"test.npy\")\n",
    ").squeeze()\n",
    "\n",
    "## Load labels\n",
    "dir = os.path.join(DATASETS_DIR, DATASET_NAME)\n",
    "train_data = pd.read_csv(os.path.join(dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(dir, \"test.csv\"))\n",
    "\n",
    "train_labels = np.array(train_data[\"label\"])\n",
    "test_labels = np.array(test_data[\"label\"])\n",
    "\n",
    "## Load Model\n",
    "model_path = SAVED_MODELS_DIR / DATASET_NAME / \"LogisticRegression.pkl\"\n",
    "model = load_pickle(model_path)\n",
    "    \n",
    "\n",
    "name = \"yang_fast\"\n",
    "filename = f\"results/{DATASET_NAME}/{DATASET_NAME}_{name}.pkl\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=model,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_embeddings,\n",
    "    train_labels=train_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=np.arange(len(test_labels))\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'results/{DATASET_NAME}/{name}_metrics.json'\n",
    "pickle_file_path = f'results/{DATASET_NAME}/{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [30:13<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/753 identified subsets are valid\n",
      "Overall validity is 603/1000, or 60.3%\n",
      "Precision validity is 603/753, or 80.08%\n",
      "Identified 753/1000 subsets.\n",
      "Coverage: 75.3%\n",
      "Median Valid Subset Sizes is 213.0, out of 603 valid subsets\n",
      "{'Coverage': 75.3,\n",
      " 'Median Size': 213.0,\n",
      " 'Overall Validity': 60.3,\n",
      " 'Precision Validity': 80.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate tweets, yang slow\n",
    "\n",
    "from utils.constants.directory import SAVED_MODELS_DIR, EMBEDDINGS_DIR, DATASETS_DIR\n",
    "from utils.io import load_pickle\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"tweets\"\n",
    "\n",
    "## Load Embeddings\n",
    "embeddings_path = os.path.join(EMBEDDINGS_DIR, DATASET_NAME)\n",
    "train_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"train.npy\")\n",
    ").squeeze()\n",
    "\n",
    "test_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"test.npy\")\n",
    ").squeeze()\n",
    "\n",
    "## Load labels\n",
    "dir = os.path.join(DATASETS_DIR, DATASET_NAME)\n",
    "train_data = pd.read_csv(os.path.join(dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(dir, \"test.csv\"))\n",
    "\n",
    "train_labels = np.array(train_data[\"label\"])\n",
    "test_labels = np.array(test_data[\"label\"])\n",
    "\n",
    "## Load Model\n",
    "model_path = SAVED_MODELS_DIR / DATASET_NAME / \"LogisticRegression.pkl\"\n",
    "model = load_pickle(model_path)\n",
    "    \n",
    "\n",
    "name = \"yang_slow\"\n",
    "filename = f\"results/{DATASET_NAME}/{DATASET_NAME}_{name}.pkl\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=model,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_embeddings,\n",
    "    train_labels=train_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=np.arange(len(test_labels))\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'results/{DATASET_NAME}/{name}_metrics.json'\n",
    "pickle_file_path = f'results/{DATASET_NAME}/{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [06:13<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559/560 identified subsets are valid\n",
      "Overall validity is 559/872, or 64.11%\n",
      "Precision validity is 559/560, or 99.82%\n",
      "Identified 560/872 subsets.\n",
      "Coverage: 64.22%\n",
      "Median Valid Subset Sizes is 94.0, out of 559 valid subsets\n",
      "{'Coverage': 64.22,\n",
      " 'Median Size': 94.0,\n",
      " 'Overall Validity': 64.11,\n",
      " 'Precision Validity': 99.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate sst, yang fast\n",
    "\n",
    "from utils.constants.directory import SAVED_MODELS_DIR, EMBEDDINGS_DIR, DATASETS_DIR\n",
    "from utils.io import load_pickle\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"sst\"\n",
    "\n",
    "## Load Embeddings\n",
    "embeddings_path = os.path.join(EMBEDDINGS_DIR, DATASET_NAME)\n",
    "train_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"train.npy\")\n",
    ").squeeze()\n",
    "\n",
    "test_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"test.npy\")\n",
    ").squeeze()\n",
    "\n",
    "## Load labels\n",
    "dir = os.path.join(DATASETS_DIR, DATASET_NAME)\n",
    "train_data = pd.read_csv(os.path.join(dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(dir, \"test.csv\"))\n",
    "\n",
    "train_labels = np.array(train_data[\"label\"])\n",
    "test_labels = np.array(test_data[\"label\"])\n",
    "\n",
    "## Load Model\n",
    "model_path = SAVED_MODELS_DIR / DATASET_NAME / \"LogisticRegression.pkl\"\n",
    "model = load_pickle(model_path)\n",
    "    \n",
    "\n",
    "name = \"yang_fast\"\n",
    "filename = f\"results/{DATASET_NAME}/{DATASET_NAME}_{name}.pkl\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=model,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_embeddings,\n",
    "    train_labels=train_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=np.arange(len(test_labels))\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'results/{DATASET_NAME}/{name}_metrics.json'\n",
    "pickle_file_path = f'results/{DATASET_NAME}/{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(559, 872, 0.6410550458715596)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fname = \"./results/sst/sst_yang_fast_new_predictions.npy\"\n",
    "\n",
    "new_pred = np.load(new_fname, allow_pickle=True)\n",
    "\n",
    "old_fname = \"./results/sst/sst_yang_fast_old_predictions.npy\"\n",
    "\n",
    "old_pred = np.load(old_fname, allow_pickle=True)\n",
    "\n",
    "true_old_pred = old_pred >= 0.5\n",
    "\n",
    "is_valid_3 = []\n",
    "for po, pn in zip(true_old_pred, new_pred):\n",
    "    if pn is None:\n",
    "        is_valid_3.append(False)\n",
    "        continue\n",
    "    pr = pn >= 0.5\n",
    "    # print(pr, po[0])\n",
    "    if pr != po[0]:\n",
    "        is_valid_3.append(True)\n",
    "    else:\n",
    "        is_valid_3.append(False)\n",
    "\n",
    "is_valid_3 = np.array(is_valid_3)\n",
    "sum(is_valid_3), is_valid_3.size, sum(is_valid_3)/is_valid_3.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [06:28<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551/560 identified subsets are valid\n",
      "Overall validity is 551/872, or 63.19%\n",
      "Precision validity is 551/560, or 98.39%\n",
      "Identified 560/872 subsets.\n",
      "Coverage: 64.22%\n",
      "Median Valid Subset Sizes is 76.0, out of 551 valid subsets\n",
      "{'Coverage': 64.22,\n",
      " 'Median Size': 76.0,\n",
      " 'Overall Validity': 63.19,\n",
      " 'Precision Validity': 98.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate sst, yang slow\n",
    "\n",
    "from utils.constants.directory import SAVED_MODELS_DIR, EMBEDDINGS_DIR, DATASETS_DIR\n",
    "from utils.io import load_pickle\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"sst\"\n",
    "\n",
    "## Load Embeddings\n",
    "embeddings_path = os.path.join(EMBEDDINGS_DIR, DATASET_NAME)\n",
    "train_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"train.npy\")\n",
    ").squeeze()\n",
    "\n",
    "test_embeddings = np.load(\n",
    "    os.path.join(embeddings_path, \"test.npy\")\n",
    ").squeeze()\n",
    "\n",
    "## Load labels\n",
    "dir = os.path.join(DATASETS_DIR, DATASET_NAME)\n",
    "train_data = pd.read_csv(os.path.join(dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(dir, \"test.csv\"))\n",
    "\n",
    "train_labels = np.array(train_data[\"label\"])\n",
    "test_labels = np.array(test_data[\"label\"])\n",
    "\n",
    "## Load Model\n",
    "model_path = SAVED_MODELS_DIR / DATASET_NAME / \"LogisticRegression.pkl\"\n",
    "model = load_pickle(model_path)\n",
    "    \n",
    "\n",
    "name = \"yang_slow\"\n",
    "filename = f\"results/{DATASET_NAME}/{DATASET_NAME}_{name}.pkl\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=model,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_embeddings,\n",
    "    train_labels=train_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=np.arange(len(test_labels))\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'results/{DATASET_NAME}/{name}_metrics.json'\n",
    "pickle_file_path = f'results/{DATASET_NAME}/{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470, 872, 0.5389908256880734)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fname = \"./results/sst/sst_yang_slow_new_predictions.npy\"\n",
    "\n",
    "new_pred = np.load(new_fname, allow_pickle=True)\n",
    "\n",
    "old_fname = \"./results/sst/sst_yang_slow_old_predictions.npy\"\n",
    "\n",
    "old_pred = np.load(old_fname, allow_pickle=True)\n",
    "\n",
    "true_old_pred = old_pred >= 0.5\n",
    "\n",
    "is_valid_3 = []\n",
    "for po, pn in zip(true_old_pred, new_pred):\n",
    "    if pn is None:\n",
    "        is_valid_3.append(False)\n",
    "        continue\n",
    "    pr = pn >= 0.5\n",
    "    # print(pr, po[0])\n",
    "    if pr != po[0]:\n",
    "        is_valid_3.append(True)\n",
    "    else:\n",
    "        is_valid_3.append(False)\n",
    "\n",
    "is_valid_3 = np.array(is_valid_3)\n",
    "sum(is_valid_3), is_valid_3.size, sum(is_valid_3)/is_valid_3.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrapperbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
