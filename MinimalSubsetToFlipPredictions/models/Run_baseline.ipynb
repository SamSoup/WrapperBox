{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Runner\n",
    "\n",
    "Runs the baseline for each of the proposed method:\n",
    "\n",
    "| Classifier | Approach              | Coverage (% identified) | Validity (% identified and leads to flip) | Median Size |\n",
    "|------------|-----------------------|--------------------------|--------------------------------------------|-------------|\n",
    "| Logistic   | Class Exclusion       |                          |                                            |             |\n",
    "| Logistic   | Fast + CE fallback    |                          |                                            |             |\n",
    "| Logistic   | Slow + CE fallback    |                          |                                            |             |\n",
    "| KNN        | Class Exclusion       |                          |                                            |             |\n",
    "| KNN        | Greedy + CE fallback  |                          |                                            |             |\n",
    "| SVM        | Class Exclusion       |                          |                                            |             |\n",
    "| SVM        | Greedy + CE fallback  |                          |                                            |             |\n",
    "| DT         | Class Exclusion       |                          |                                            |             |\n",
    "| DT         | Greedy + CE fallback  |                          |                                            |             |\n",
    "| LMeans     | Class Exclusion       |                          |                                            |             |\n",
    "| LMeans     | Greedy + CE fallback  |                          |                                            |             |\n",
    "\n",
    "Note that running class exclusion + a random baseline does not make any sense, \n",
    "since if the random classifier is deterministic (fixed seed), then any removal\n",
    "would not be valid. Otherwise, validity is stochastic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DATASET_NAME = \"esnli\"\n",
    "LABEL_SPACE = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "MODEL_NAME = \"deberta_large\"\n",
    "SEED = 42\n",
    "POOLER = \"mean_with_attention\"\n",
    "LAYER = 24\n",
    "\n",
    "from MinimalSubsetToFlipPredictions.models.SimpleBaseline import FindMinimalSubsetSimpleBaseline\n",
    "\n",
    "\n",
    "ce_finder = FindMinimalSubsetSimpleBaseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Embeddings\n",
    "from utils.io import (\n",
    "    load_dataset_from_hf,\n",
    "    load_labels_at_split,\n",
    "    load_embeddings,\n",
    ")\n",
    "import numpy as np\n",
    "train_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"train\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "eval_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"eval\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "test_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"test\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "train_eval_embeddings = np.vstack([train_embeddings, eval_embeddings])\n",
    "\n",
    "## Load Datasets and Labels\n",
    "dataset = load_dataset_from_hf(dataset=DATASET_NAME)\n",
    "train_labels = load_labels_at_split(dataset, \"train\")\n",
    "eval_labels = load_labels_at_split(dataset, \"eval\")\n",
    "train_eval_labels = np.concatenate([train_labels, eval_labels])\n",
    "test_labels = load_labels_at_split(dataset, \"test\")\n",
    "\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "train_eval_dataset = concatenate_datasets([dataset[\"train\"], dataset[\"eval\"]])\n",
    "dataset_dict = DatasetDict(\n",
    "    {\"train\": train_eval_dataset, \"test\": dataset[\"test\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Logistic with Class Exclusion\n",
    "from utils.io import load_wrapperbox\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LogisticRegression\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "subsets = ce_finder.find_minimal_subset(\n",
    "    clf=clf, \n",
    "    train_embeddings=train_eval_embeddings, \n",
    "    test_embeddings=test_embeddings, \n",
    "    train_labels=train_eval_labels\n",
    ")\n",
    "\n",
    "output_file = f\"{DATASET_NAME}_{MODEL_NAME}_{wrapper_name}_baseline.pickle\"\n",
    "with open(output_file, 'wb') as handle:\n",
    "    pickle.dump(subsets, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_eval_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m      6\u001b[0m wrapper_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogisticRegression\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m clf \u001b[38;5;241m=\u001b[39m load_wrapperbox(\n\u001b[1;32m      8\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mDATASET_NAME,\n\u001b[1;32m      9\u001b[0m     model\u001b[38;5;241m=\u001b[39mMODEL_NAME,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     wrapperbox\u001b[38;5;241m=\u001b[39mwrapper_name\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m subsets \u001b[38;5;241m=\u001b[39m ce_finder\u001b[38;5;241m.\u001b[39mfind_minimal_subset(\n\u001b[1;32m     16\u001b[0m     clf\u001b[38;5;241m=\u001b[39mclf, \n\u001b[0;32m---> 17\u001b[0m     train_embeddings\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_eval_embeddings\u001b[49m, \n\u001b[1;32m     18\u001b[0m     test_embeddings\u001b[38;5;241m=\u001b[39mtest_embeddings, \n\u001b[1;32m     19\u001b[0m     train_labels\u001b[38;5;241m=\u001b[39mtrain_eval_labels\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myang2023_fast\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m flip_list_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_eval_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "## Run Logistic with Yang fast + Class Exclusion as a fall back mechanism\n",
    "\n",
    "from utils.io import load_pickle\n",
    "from utils.io import load_wrapperbox\n",
    "\n",
    "wrapper_name = \"LogisticRegression\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "subsets = ce_finder.find_minimal_subset(\n",
    "    clf=clf, \n",
    "    train_embeddings=train_eval_embeddings, \n",
    "    test_embeddings=test_embeddings, \n",
    "    train_labels=train_eval_labels\n",
    ")\n",
    "\n",
    "name = \"yang2023_fast\"\n",
    "flip_list_filename = f\"{DATASET_NAME}_{MODEL_NAME}_{name}.pickle\"\n",
    "flip_list = load_pickle(flip_list_filename)\n",
    "\n",
    "# whenever the fliplist is none or empty, fall back to baseline\n",
    "true_flip_list = []\n",
    "for i, l in enumerate(flip_list):\n",
    "    if l is None or len(l) == 0:\n",
    "        true_flip_list.append(subsets[i])\n",
    "    else:\n",
    "        true_flip_list.append(l)\n",
    "\n",
    "output_file = f\"{DATASET_NAME}_{MODEL_NAME}_{name}_baseline_fallback.pickle\"\n",
    "with open(output_file, 'wb') as handle:\n",
    "    pickle.dump(true_flip_list, handle)\n",
    "\n",
    "print(f\"Saved results to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samsoup/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.1.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Run KNN with Class Exclusion\n",
    "from classifiers import RandomClassifier\n",
    "from utils.io import load_wrapperbox\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"KNN\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "subsets = ce_finder.find_minimal_subset(\n",
    "    clf=clf, \n",
    "    train_embeddings=train_eval_embeddings, \n",
    "    test_embeddings=test_embeddings, \n",
    "    train_labels=train_eval_labels\n",
    ")\n",
    "\n",
    "output_file = f\"{DATASET_NAME}_{MODEL_NAME}_{wrapper_name}_baseline.pickle\"\n",
    "with open(output_file, 'wb') as handle:\n",
    "    pickle.dump(subsets, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samsoup/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LinearSVC from version 1.1.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Run SVM with Class Exclusion\n",
    "from classifiers import RandomClassifier\n",
    "from utils.io import load_wrapperbox\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"SVM\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "subsets = ce_finder.find_minimal_subset(\n",
    "    clf=clf, \n",
    "    train_embeddings=train_eval_embeddings, \n",
    "    test_embeddings=test_embeddings, \n",
    "    train_labels=train_eval_labels\n",
    ")\n",
    "\n",
    "output_file = f\"{DATASET_NAME}_{MODEL_NAME}_{wrapper_name}_baseline.pickle\"\n",
    "with open(output_file, 'wb') as handle:\n",
    "    pickle.dump(subsets, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run LGBM with Class Exclusion\n",
    "from classifiers import RandomClassifier\n",
    "from utils.io import load_wrapperbox\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LGBM\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "subsets = ce_finder.find_minimal_subset(\n",
    "    clf=clf, \n",
    "    train_embeddings=train_eval_embeddings, \n",
    "    test_embeddings=test_embeddings, \n",
    "    train_labels=train_eval_labels\n",
    ")\n",
    "\n",
    "output_file = f\"{DATASET_NAME}_{MODEL_NAME}_{wrapper_name}_baseline.pickle\"\n",
    "\n",
    "with open(output_file, 'wb') as handle:\n",
    "    pickle.dump(subsets, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run LMeans with Class Exclusion\n",
    "from classifiers import RandomClassifier\n",
    "from utils.io import load_wrapperbox\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LMeans\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "subsets = ce_finder.find_minimal_subset(\n",
    "    clf=clf, \n",
    "    train_embeddings=train_eval_embeddings, \n",
    "    test_embeddings=test_embeddings, \n",
    "    train_labels=train_eval_labels\n",
    ")\n",
    "\n",
    "output_file = f\"{DATASET_NAME}_{MODEL_NAME}_{wrapper_name}_baseline.pickle\"\n",
    "with open(output_file, 'wb') as handle:\n",
    "    pickle.dump(subsets, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrapperbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
