{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Approaches\n",
    "\n",
    "This notebook verifies if identified subsets are valid.\n",
    "\n",
    "An empty (or None) subset is automatically invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "DATASET_NAME = \"toxigen\"\n",
    "LABEL_SPACE = [\"non-toxic\", \"toxic\", \"contradiction\"]\n",
    "MODEL_NAME = \"deberta_large\"\n",
    "SEED = 42\n",
    "POOLER = \"mean_with_attention\"\n",
    "LAYER = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/samsoup/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samsoup/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Load Embeddings\n",
    "from utils.io import (\n",
    "    load_dataset_from_hf,\n",
    "    load_labels_at_split,\n",
    "    load_embeddings,\n",
    "    load_wrapperbox\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"train\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "eval_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"eval\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "test_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"test\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "train_eval_embeddings = np.vstack([train_embeddings, eval_embeddings])\n",
    "\n",
    "\n",
    "## Load Datasets and Labels\n",
    "dataset = load_dataset_from_hf(dataset=DATASET_NAME)\n",
    "train_labels = load_labels_at_split(dataset, \"train\")\n",
    "eval_labels = load_labels_at_split(dataset, \"eval\")\n",
    "train_eval_labels = np.concatenate([train_labels, eval_labels])\n",
    "test_labels = load_labels_at_split(dataset, \"test\")\n",
    "\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "train_eval_dataset = concatenate_datasets([dataset[\"train\"], dataset[\"eval\"]])\n",
    "dataset_dict = DatasetDict(\n",
    "    {\"train\": train_eval_dataset, \"test\": dataset[\"test\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/940 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     flip_list \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[1;32m     22\u001b[0m ex_indices_to_check \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(flip_list))\n\u001b[0;32m---> 23\u001b[0m is_valid \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_predictions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflip_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflip_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_eval_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_eval_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mex_indices_to_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_indices_to_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m metrics \u001b[38;5;241m=\u001b[39m compute_subset_metrics(\n\u001b[1;32m     33\u001b[0m     flip_list\u001b[38;5;241m=\u001b[39mflip_list,\n\u001b[1;32m     34\u001b[0m     is_valid\u001b[38;5;241m=\u001b[39mis_valid\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m pprint(metrics)\n",
      "File \u001b[0;32m~/Work/WrapperBox/MinimalSubsetToFlipPredictions/evaluate/evaluate.py:44\u001b[0m, in \u001b[0;36mevaluate_predictions\u001b[0;34m(clf, flip_list, train_embeddings, train_labels, test_embeddings, ex_indices_to_check)\u001b[0m\n\u001b[1;32m     42\u001b[0m         is_valid_subsets\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     _, _, is_valid_subset \u001b[38;5;241m=\u001b[39m \u001b[43mretrain_and_evaluate_validity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_ex_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices_to_exclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     is_valid_subsets\u001b[38;5;241m.\u001b[39mappend(is_valid_subset)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_valid_subsets\n",
      "File \u001b[0;32m~/Work/WrapperBox/MinimalSubsetToFlipPredictions/evaluate/evaluate.py:23\u001b[0m, in \u001b[0;36mretrain_and_evaluate_validity\u001b[0;34m(clf, train_embeddings, train_labels, x_test, indices_to_exclude)\u001b[0m\n\u001b[1;32m     21\u001b[0m old_pred \u001b[38;5;241m=\u001b[39m get_predictions(clf, x_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     22\u001b[0m new_clf \u001b[38;5;241m=\u001b[39m clone(clf)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mnew_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduced_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduced_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m new_pred \u001b[38;5;241m=\u001b[39m get_predictions(new_clf, x_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# this subset is valid only if new prediction does not equal old prediction\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1246\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1244\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1250\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1251\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1254\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "## Do metrics for Logistic Regression baseline with purely class exclusion\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LogisticRegression\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "name = \"LogisticRegression_baseline\"\n",
    "filename = f\"{DATASET_NAME}_{MODEL_NAME}_{name}.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "ex_indices_to_check = np.arange(len(flip_list))\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_metrics.json'\n",
    "pickle_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 940/940 [01:20<00:00, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/931 identified subsets are valid\n",
      "Overall validity is 5/940, or 0.53%\n",
      "Precision validity is 5/931, or 0.54%\n",
      "Identified 931/940 subsets.\n",
      "Coverage: 99.04%\n",
      "Median Valid Subset Sizes is 2430.0, out of 5 valid subsets\n",
      "{'Coverage': 99.04,\n",
      " 'Median Size': 2430.0,\n",
      " 'Overall Validity': 0.53,\n",
      " 'Precision Validity': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Do metrics for Yang fast\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LogisticRegression\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "name = \"yang_fast\"\n",
    "filename = f\"{DATASET_NAME}_{MODEL_NAME}_{name}.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "ex_indices_to_check = np.arange(len(flip_list))\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_metrics.json'\n",
    "pickle_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)\n",
    "\n",
    "print(f\"Saved to {pickle_file_path} and {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pickle_file_path, 'rb') as pickle_file:\n",
    "    x = pickle.load(pickle_file)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do metrics for Yang fast, with class exclusion as a fall back\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LogisticRegression\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "name = \"yang_fast\"\n",
    "filename = f\"{DATASET_NAME}_{MODEL_NAME}_{name}.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "ex_indices_to_check = np.arange(len(flip_list))\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_metrics.json'\n",
    "pickle_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 940/940 [00:04<00:00, 195.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/48 identified subsets are valid\n",
      "Overall validity is 2/940, or 0.21%\n",
      "Precision validity is 2/48, or 4.17%\n",
      "Identified 48/940 subsets.\n",
      "Coverage: 5.11%\n",
      "Median Valid Subset Sizes is 90.5, out of 2 valid subsets\n",
      "{'Coverage': 5.11,\n",
      " 'Median Size': 90.5,\n",
      " 'Overall Validity': 0.21,\n",
      " 'Precision Validity': 4.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Do metrics for Yang slow\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LogisticRegression\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "name = \"yang_slow\"\n",
    "filename = f\"{DATASET_NAME}_{MODEL_NAME}_{name}.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "ex_indices_to_check = np.arange(len(flip_list))\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_metrics.json'\n",
    "pickle_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samsoup/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.1.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "100%|██████████| 940/940 [00:16<00:00, 57.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940/940 identified subsets are valid\n",
      "Overall validity is 940/940, or 100.0%\n",
      "Precision validity is 940/940, or 100.0%\n",
      "Identified 940/940 subsets.\n",
      "Coverage: 100.0%\n",
      "Median Valid Subset Sizes is 6144.0, out of 940 valid subsets\n",
      "{'Coverage': 100.0,\n",
      " 'Median Size': 6144.0,\n",
      " 'Overall Validity': 100.0,\n",
      " 'Precision Validity': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Do metrics for KNN\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"KNN\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "name = \"KNN\"\n",
    "filename = f\"{DATASET_NAME}_{MODEL_NAME}_{name}.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "ex_indices_to_check = np.arange(len(flip_list))\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_metrics.json'\n",
    "pickle_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/940 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1414, number of negative: 6760\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8174, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.172988 -> initscore=-1.564600\n",
      "[LightGBM] [Info] Start training from score -1.564600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/940 [00:00<00:28, 32.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2172, number of negative: 6776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8948, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242736 -> initscore=-1.137739\n",
      "[LightGBM] [Info] Start training from score -1.137739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/940 [00:01<01:21, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1595, number of negative: 6766\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8361, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190767 -> initscore=-1.445036\n",
      "[LightGBM] [Info] Start training from score -1.445036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/940 [00:02<01:45,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 50/940 [00:03<00:50, 17.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2169, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8950, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242346 -> initscore=-1.139858\n",
      "[LightGBM] [Info] Start training from score -1.139858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 60/940 [00:03<00:49, 17.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8957, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243050 -> initscore=-1.136029\n",
      "[LightGBM] [Info] Start training from score -1.136029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 62/940 [00:04<01:05, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6774\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8952, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243298 -> initscore=-1.134685\n",
      "[LightGBM] [Info] Start training from score -1.134685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 65/940 [00:04<01:19, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2173, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8955, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242658 -> initscore=-1.138163\n",
      "[LightGBM] [Info] Start training from score -1.138163\n",
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8958, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243023 -> initscore=-1.136177\n",
      "[LightGBM] [Info] Start training from score -1.136177\n",
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 67/940 [00:06<02:29,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 70/940 [00:06<02:38,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2174, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8956, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242742 -> initscore=-1.137703\n",
      "[LightGBM] [Info] Start training from score -1.137703\n",
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 78/940 [00:07<02:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8958, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243135 -> initscore=-1.135570\n",
      "[LightGBM] [Info] Start training from score -1.135570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 80/940 [00:09<03:09,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8958, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243135 -> initscore=-1.135570\n",
      "[LightGBM] [Info] Start training from score -1.135570\n",
      "[LightGBM] [Info] Number of positive: 2176, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8958, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242911 -> initscore=-1.136784\n",
      "[LightGBM] [Info] Start training from score -1.136784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 97/940 [00:09<01:18, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 107/940 [00:10<01:09, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8957, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243050 -> initscore=-1.136029\n",
      "[LightGBM] [Info] Start training from score -1.136029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 118/940 [00:11<01:15, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 120/940 [00:12<01:32,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 126/940 [00:12<01:31,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8923, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243976 -> initscore=-1.131002\n",
      "[LightGBM] [Info] Start training from score -1.131002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 153/940 [00:13<00:40, 19.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8958, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243023 -> initscore=-1.136177\n",
      "[LightGBM] [Info] Start training from score -1.136177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 156/940 [00:13<00:51, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2108, number of negative: 6777\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8885, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.237254 -> initscore=-1.167795\n",
      "[LightGBM] [Info] Start training from score -1.167795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 163/940 [00:14<00:54, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n",
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8957, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243162 -> initscore=-1.135423\n",
      "[LightGBM] [Info] Start training from score -1.135423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 170/940 [00:15<00:59, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 173/940 [00:15<01:14, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2166, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8948, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242065 -> initscore=-1.141390\n",
      "[LightGBM] [Info] Start training from score -1.141390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 175/940 [00:16<01:42,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6777\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8955, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243216 -> initscore=-1.135128\n",
      "[LightGBM] [Info] Start training from score -1.135128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 187/940 [00:18<01:34,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2169, number of negative: 6776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8945, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242482 -> initscore=-1.139121\n",
      "[LightGBM] [Info] Start training from score -1.139121\n",
      "[LightGBM] [Info] Number of positive: 2176, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8957, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242938 -> initscore=-1.136636\n",
      "[LightGBM] [Info] Start training from score -1.136636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 190/940 [00:18<01:47,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2173, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8955, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242658 -> initscore=-1.138163\n",
      "[LightGBM] [Info] Start training from score -1.138163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 202/940 [00:19<01:28,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n",
      "[LightGBM] [Info] Number of positive: 2140, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8921, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239883 -> initscore=-1.153319\n",
      "[LightGBM] [Info] Start training from score -1.153319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 209/940 [00:21<01:40,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8957, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243050 -> initscore=-1.136029\n",
      "[LightGBM] [Info] Start training from score -1.136029\n",
      "[LightGBM] [Info] Number of positive: 2176, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8957, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242938 -> initscore=-1.136636\n",
      "[LightGBM] [Info] Start training from score -1.136636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 220/940 [00:22<01:20,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6777\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8954, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243132 -> initscore=-1.135587\n",
      "[LightGBM] [Info] Start training from score -1.135587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 227/940 [00:22<01:10, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8958, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243135 -> initscore=-1.135570\n",
      "[LightGBM] [Info] Start training from score -1.135570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 245/940 [00:23<00:40, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 248/940 [00:23<00:52, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 261/940 [00:24<00:41, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 268/940 [00:24<00:44, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2163, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8945, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241811 -> initscore=-1.142776\n",
      "[LightGBM] [Info] Start training from score -1.142776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 270/940 [00:25<00:56, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 284/940 [00:26<00:40, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2173, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8955, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242658 -> initscore=-1.138163\n",
      "[LightGBM] [Info] Start training from score -1.138163\n",
      "[LightGBM] [Info] Number of positive: 2173, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.153482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8955, number of used features: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 289/940 [00:26<00:47, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242658 -> initscore=-1.138163\n",
      "[LightGBM] [Info] Start training from score -1.138163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 291/940 [00:27<01:01, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8957, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243162 -> initscore=-1.135423\n",
      "[LightGBM] [Info] Start training from score -1.135423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 293/940 [00:27<01:14,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6778\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8956, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243189 -> initscore=-1.135275\n",
      "[LightGBM] [Info] Start training from score -1.135275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 294/940 [00:28<01:36,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2158, number of negative: 6388\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8546, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.252516 -> initscore=-1.085239\n",
      "[LightGBM] [Info] Start training from score -1.085239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 295/940 [00:28<02:01,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 320/940 [00:29<00:34, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 326/940 [00:29<00:38, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n",
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 331/940 [00:30<01:03,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 342/940 [00:31<00:46, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2176, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8956, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242966 -> initscore=-1.136489\n",
      "[LightGBM] [Info] Start training from score -1.136489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 344/940 [00:32<00:58, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2172, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8952, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242627 -> initscore=-1.138329\n",
      "[LightGBM] [Info] Start training from score -1.138329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 354/940 [00:32<00:46, 12.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2176, number of negative: 6776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8952, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243074 -> initscore=-1.135899\n",
      "[LightGBM] [Info] Start training from score -1.135899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 365/940 [00:33<00:38, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2168, number of negative: 6765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8933, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242696 -> initscore=-1.137957\n",
      "[LightGBM] [Info] Start training from score -1.137957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 371/940 [00:33<00:41, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 373/940 [00:34<00:53, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6778\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8955, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243104 -> initscore=-1.135734\n",
      "[LightGBM] [Info] Start training from score -1.135734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 375/940 [00:34<01:06,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 380/940 [00:35<01:05,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8957, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243162 -> initscore=-1.135423\n",
      "[LightGBM] [Info] Start training from score -1.135423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 386/940 [00:35<00:59,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 387/940 [00:36<01:23,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2166, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8947, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242092 -> initscore=-1.141242\n",
      "[LightGBM] [Info] Start training from score -1.141242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 390/940 [00:37<01:26,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 397/940 [00:37<01:08,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2124, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8905, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.238518 -> initscore=-1.160823\n",
      "[LightGBM] [Info] Start training from score -1.160823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 407/940 [00:38<00:48, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 413/940 [00:38<00:49, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2175, number of negative: 6779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8954, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242908 -> initscore=-1.136801\n",
      "[LightGBM] [Info] Start training from score -1.136801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 416/940 [00:39<00:56,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2115, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8895, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.237774 -> initscore=-1.164922\n",
      "[LightGBM] [Info] Start training from score -1.164922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 420/940 [00:39<00:58,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2050, number of negative: 6779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8829, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.232189 -> initscore=-1.195990\n",
      "[LightGBM] [Info] Start training from score -1.195990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 436/940 [00:40<00:33, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2171, number of negative: 6774\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8945, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242705 -> initscore=-1.137904\n",
      "[LightGBM] [Info] Start training from score -1.137904\n",
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6751\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8928, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243840 -> initscore=-1.131743\n",
      "[LightGBM] [Info] Start training from score -1.131743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 456/940 [00:41<00:29, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6777\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8955, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243216 -> initscore=-1.135128\n",
      "[LightGBM] [Info] Start training from score -1.135128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 462/940 [00:42<00:31, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 475/940 [00:42<00:26, 17.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2172, number of negative: 6776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8948, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242736 -> initscore=-1.137739\n",
      "[LightGBM] [Info] Start training from score -1.137739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 479/940 [00:43<00:32, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8958, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243023 -> initscore=-1.136177\n",
      "[LightGBM] [Info] Start training from score -1.136177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 481/940 [00:43<00:40, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2160, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8941, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241584 -> initscore=-1.144016\n",
      "[LightGBM] [Info] Start training from score -1.144016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 483/940 [00:44<00:49,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 492/940 [00:44<00:38, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1973, number of negative: 6771\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8744, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225640 -> initscore=-1.233094\n",
      "[LightGBM] [Info] Start training from score -1.233094\n",
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6773\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8950, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243240 -> initscore=-1.134996\n",
      "[LightGBM] [Info] Start training from score -1.134996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 574/940 [00:45<00:08, 40.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n",
      "[LightGBM] [Info] Number of positive: 2122, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8902, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.238373 -> initscore=-1.161618\n",
      "[LightGBM] [Info] Start training from score -1.161618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 583/940 [00:47<00:15, 23.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n",
      "[LightGBM] [Info] Number of positive: 2174, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8956, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242742 -> initscore=-1.137703\n",
      "[LightGBM] [Info] Start training from score -1.137703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 586/940 [00:48<00:24, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2127, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8907, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.238801 -> initscore=-1.159265\n",
      "[LightGBM] [Info] Start training from score -1.159265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 588/940 [00:48<00:29, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 593/940 [00:49<00:29, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2160, number of negative: 4676\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 6836, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.315974 -> initscore=-0.772335\n",
      "[LightGBM] [Info] Start training from score -0.772335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 611/940 [00:49<00:18, 17.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2174, number of negative: 6770\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8944, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243068 -> initscore=-1.135932\n",
      "[LightGBM] [Info] Start training from score -1.135932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 617/940 [00:50<00:20, 15.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2085, number of negative: 6779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8864, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.235221 -> initscore=-1.179061\n",
      "[LightGBM] [Info] Start training from score -1.179061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 634/940 [00:50<00:14, 20.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2002, number of negative: 6772\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8774, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.228174 -> initscore=-1.218650\n",
      "[LightGBM] [Info] Start training from score -1.218650\n",
      "[LightGBM] [Info] Number of positive: 2176, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8957, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242938 -> initscore=-1.136636\n",
      "[LightGBM] [Info] Start training from score -1.136636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 637/940 [00:51<00:25, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8958, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243135 -> initscore=-1.135570\n",
      "[LightGBM] [Info] Start training from score -1.135570\n",
      "[LightGBM] [Info] Number of positive: 2175, number of negative: 6779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8954, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242908 -> initscore=-1.136801\n",
      "[LightGBM] [Info] Start training from score -1.136801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 640/940 [00:52<00:29, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8958, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243023 -> initscore=-1.136177\n",
      "[LightGBM] [Info] Start training from score -1.136177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 657/940 [00:53<00:18, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2139, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8921, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239771 -> initscore=-1.153934\n",
      "[LightGBM] [Info] Start training from score -1.153934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 675/940 [00:54<00:17, 14.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2169, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8951, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242319 -> initscore=-1.140006\n",
      "[LightGBM] [Info] Start training from score -1.140006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 687/940 [00:54<00:14, 16.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8956, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243077 -> initscore=-1.135882\n",
      "[LightGBM] [Info] Start training from score -1.135882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 698/940 [00:55<00:13, 17.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 714/940 [00:56<00:10, 20.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 719/940 [00:56<00:12, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1672, number of negative: 6764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.198198 -> initscore=-1.397594\n",
      "[LightGBM] [Info] Start training from score -1.397594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 721/940 [00:57<00:15, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8958, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243135 -> initscore=-1.135570\n",
      "[LightGBM] [Info] Start training from score -1.135570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 723/940 [00:57<00:20, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6743\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8920, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244058 -> initscore=-1.130557\n",
      "[LightGBM] [Info] Start training from score -1.130557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 725/940 [00:58<00:25,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2173, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8953, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242712 -> initscore=-1.137868\n",
      "[LightGBM] [Info] Start training from score -1.137868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 731/940 [00:58<00:23,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 734/940 [00:59<00:25,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2152, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8933, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240905 -> initscore=-1.147727\n",
      "[LightGBM] [Info] Start training from score -1.147727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 737/940 [01:00<00:29,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 754/940 [01:00<00:12, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2161, number of negative: 4600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 6761, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.319627 -> initscore=-0.755485\n",
      "[LightGBM] [Info] Start training from score -0.755485\n",
      "[LightGBM] [Info] Number of positive: 2165, number of negative: 6778\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8943, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242089 -> initscore=-1.141262\n",
      "[LightGBM] [Info] Start training from score -1.141262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 767/940 [01:01<00:13, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2175, number of negative: 6761\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8936, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243397 -> initscore=-1.134142\n",
      "[LightGBM] [Info] Start training from score -1.134142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 771/940 [01:02<00:15, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n",
      "[LightGBM] [Info] Number of positive: 2065, number of negative: 6778\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8843, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.233518 -> initscore=-1.188552\n",
      "[LightGBM] [Info] Start training from score -1.188552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 797/940 [01:03<00:08, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243107 -> initscore=-1.135718\n",
      "[LightGBM] [Info] Start training from score -1.135718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 803/940 [01:03<00:09, 14.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 812/940 [01:04<00:08, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8959, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242996 -> initscore=-1.136324\n",
      "[LightGBM] [Info] Start training from score -1.136324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 846/940 [01:04<00:03, 29.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2175, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8957, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242827 -> initscore=-1.137243\n",
      "[LightGBM] [Info] Start training from score -1.137243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 853/940 [01:05<00:03, 24.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2174, number of negative: 6768\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8942, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243122 -> initscore=-1.135637\n",
      "[LightGBM] [Info] Start training from score -1.135637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 863/940 [01:06<00:03, 22.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2176, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8958, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242911 -> initscore=-1.136784\n",
      "[LightGBM] [Info] Start training from score -1.136784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 869/940 [01:06<00:03, 18.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2151, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8932, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240820 -> initscore=-1.148192\n",
      "[LightGBM] [Info] Start training from score -1.148192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 871/940 [01:07<00:04, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2178, number of negative: 6774\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8952, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243298 -> initscore=-1.134685\n",
      "[LightGBM] [Info] Start training from score -1.134685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 875/940 [01:07<00:05, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2174, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8956, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242742 -> initscore=-1.137703\n",
      "[LightGBM] [Info] Start training from score -1.137703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 890/940 [01:08<00:03, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2177, number of negative: 6777\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8954, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243132 -> initscore=-1.135587\n",
      "[LightGBM] [Info] Start training from score -1.135587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 892/940 [01:08<00:03, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2173, number of negative: 6772\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8945, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242929 -> initscore=-1.136688\n",
      "[LightGBM] [Info] Start training from score -1.136688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 896/940 [01:09<00:03, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2176, number of negative: 6781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8957, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242938 -> initscore=-1.136636\n",
      "[LightGBM] [Info] Start training from score -1.136636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 898/940 [01:09<00:04,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2175, number of negative: 5666\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 7841, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.277388 -> initscore=-0.957455\n",
      "[LightGBM] [Info] Start training from score -0.957455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 913/940 [01:10<00:01, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2175, number of negative: 6780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8955, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242881 -> initscore=-1.136948\n",
      "[LightGBM] [Info] Start training from score -1.136948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 921/940 [01:10<00:01, 14.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2167, number of negative: 6779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8946, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242231 -> initscore=-1.140486\n",
      "[LightGBM] [Info] Start training from score -1.140486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 929/940 [01:11<00:00, 14.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2172, number of negative: 6779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8951, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242654 -> initscore=-1.138181\n",
      "[LightGBM] [Info] Start training from score -1.138181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 934/940 [01:11<00:00, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2173, number of negative: 6779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8952, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242739 -> initscore=-1.137721\n",
      "[LightGBM] [Info] Start training from score -1.137721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 940/940 [01:12<00:00, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2174, number of negative: 6782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 8956, number of used features: 1024\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242742 -> initscore=-1.137703\n",
      "[LightGBM] [Info] Start training from score -1.137703\n",
      "126/126 identified subsets are valid\n",
      "Overall validity is 126/940, or 13.4%\n",
      "Precision validity is 126/126, or 100.0%\n",
      "Identified 126/940 subsets.\n",
      "Coverage: 13.4%\n",
      "Median Valid Subset Sizes is 4.0, out of 126 valid subsets\n",
      "{'Coverage': 13.4,\n",
      " 'Median Size': 4.0,\n",
      " 'Overall Validity': 13.4,\n",
      " 'Precision Validity': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Do metrics for LGBM\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LGBM\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "name = \"LGBM\"\n",
    "filename = f\"{DATASET_NAME}_{MODEL_NAME}_{name}.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "ex_indices_to_check = np.arange(len(flip_list))\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_metrics.json'\n",
    "pickle_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 940/940 [01:09<00:00, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940/940 identified subsets are valid\n",
      "Overall validity is 940/940, or 100.0%\n",
      "Precision validity is 940/940, or 100.0%\n",
      "Identified 940/940 subsets.\n",
      "Coverage: 100.0%\n",
      "Median Valid Subset Sizes is 6339.0, out of 940 valid subsets\n",
      "{'Coverage': 100.0,\n",
      " 'Median Size': 6339.0,\n",
      " 'Overall Validity': 100.0,\n",
      " 'Precision Validity': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Do metrics for LMeans\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions, compute_subset_metrics\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LMeans\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "name = \"LMeans\"\n",
    "filename = f\"{DATASET_NAME}_{MODEL_NAME}_{name}.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "ex_indices_to_check = np.arange(len(flip_list))\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = compute_subset_metrics(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# Path to the output files\n",
    "json_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_metrics.json'\n",
    "pickle_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{name}_is_valid.pickle'\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(is_valid, pickle_file)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrapperbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
