{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to check some results where the validity is not 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Validity</th>\n",
       "      <th>Median Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>Fast</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>Slow</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Greedy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Greedy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>Greedy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LMeans</td>\n",
       "      <td>Greedy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier Approach Coverage Validity Median Size\n",
       "0   Logistic     Fast                              \n",
       "1   Logistic     Slow                              \n",
       "2        KNN   Greedy                              \n",
       "3        SVM   Greedy                              \n",
       "4         DT   Greedy                              \n",
       "5     LMeans   Greedy                              "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_classifier_df(do_CE=False):\n",
    "    # Create a list of classifiers and their base approaches\n",
    "    classifiers = [\"Logistic\", \"KNN\", \"SVM\", \"DT\", \"LMeans\"]\n",
    "    base_approaches = {\n",
    "        \"Logistic\": [\"Fast\", \"Slow\"],\n",
    "        \"KNN\": [\"Greedy\"],\n",
    "        \"SVM\": [\"Greedy\"],\n",
    "        \"DT\": [\"Greedy\"],\n",
    "        \"LMeans\": [\"Greedy\"]\n",
    "    }\n",
    "\n",
    "    # Initialize the columns\n",
    "    columns = [\"Classifier\", \"Approach\", \"Coverage\", \"Validity\", \"Median Size\"]\n",
    "\n",
    "    # Create the data list\n",
    "    data = []\n",
    "\n",
    "    # Populate the data list\n",
    "    for classifier in classifiers:\n",
    "        for approach in base_approaches[classifier]:\n",
    "            data.append([classifier, approach, \"\", \"\", \"\"])\n",
    "            \n",
    "            # Append CE fallback approach if do_CE is True\n",
    "            if do_CE:\n",
    "                ce_fallback_approach = f\"{approach} + CE fallback\"\n",
    "                data.append([classifier, ce_fallback_approach, \"\", \"\", \"\"])\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    return df\n",
    "\n",
    "df = create_classifier_df(do_CE=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"esnli\"\n",
    "LABEL_SPACE = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "MODEL_NAME = \"deberta_large\"\n",
    "SEED = 42\n",
    "POOLER = \"mean_with_attention\"\n",
    "LAYER = 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/samsoup/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samsoup/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Load Embeddings\n",
    "from utils.io import (\n",
    "    load_dataset_from_hf,\n",
    "    load_labels_at_split,\n",
    "    load_embeddings,\n",
    "    load_wrapperbox\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"train\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "eval_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"eval\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "test_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"test\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "train_eval_embeddings = np.vstack([train_embeddings, eval_embeddings])\n",
    "\n",
    "\n",
    "## Load Datasets and Labels\n",
    "dataset = load_dataset_from_hf(dataset=DATASET_NAME)\n",
    "train_labels = load_labels_at_split(dataset, \"train\")\n",
    "eval_labels = load_labels_at_split(dataset, \"eval\")\n",
    "train_eval_labels = np.concatenate([train_labels, eval_labels])\n",
    "test_labels = load_labels_at_split(dataset, \"test\")\n",
    "\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "train_eval_dataset = concatenate_datasets([dataset[\"train\"], dataset[\"eval\"]])\n",
    "dataset_dict = DatasetDict(\n",
    "    {\"train\": train_eval_dataset, \"test\": dataset[\"test\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9824"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.io import load_pickle\n",
    "\n",
    "\n",
    "# load_pickle(\"evaluate_yang_fast_compiled/esnli_deberta_large_yang_fast_0to77_is_valid_subsets.pickle\")\n",
    "len(load_pickle(\"evaluate_yang_fast_compiled/esnli_deberta_large_yang2023_fast_is_valid.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format results for Yang fast\n",
    "\n",
    "\n",
    "# Use loc to set the values\n",
    "df.loc[(df['Classifier'] == classifier) & (df['Approach'] == approach), 'Coverage (% identified)'] = new_coverage\n",
    "df.loc[(df['Classifier'] == classifier) & (df['Approach'] == approach), 'Validity (% identified and leads to flip)'] = new_validity\n",
    "df.loc[(df['Classifier'] == classifier) & (df['Approach'] == approach), 'Median Size'] = new_median_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samsoup/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.1.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([7035, 8141]),)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Format metrics for KNN\n",
    "from utils.io import load_json, load_pickle, load_wrapperbox\n",
    "import numpy as np\n",
    "\n",
    "wrapper_name = \"KNN\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "filename = f\"{DATASET_NAME}_{MODEL_NAME}_{wrapper_name}.pickle\"\n",
    "flip_list = load_pickle(filename)\n",
    "\n",
    "# (array([7035, 8141]),), pred: array([0, 0])\n",
    "is_valid = load_pickle(f\"{DATASET_NAME}_{MODEL_NAME}_{wrapper_name}_is_valid.pickle\")\n",
    "metrics = load_json(f\"{DATASET_NAME}_{MODEL_NAME}_{wrapper_name}_greedy_metrics.json\") \n",
    "# # load_json()\n",
    "np.where(np.array(is_valid) == False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298664"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flip_list[7035][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[231273, 542352,  69907, ..., 154552, 522585,   3251],\n",
       "        [418123, 465440, 215959, ..., 154552, 522585,   3251]]),\n",
       " array([[ 3.49112333,  3.57319655,  3.70255389, ..., 43.81287158,\n",
       "         43.84857804, 43.88398069],\n",
       "        [ 2.56989404,  2.5710627 ,  2.5827666 , ..., 42.79257519,\n",
       "         42.8970961 , 42.91349945]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_dists, n_neighbors = clf.kneighbors(test_embeddings[[7035, 8141]], return_distance=True, n_neighbors=train_eval_labels.size)\n",
    "n_neighbors, neigh_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([123723, 180407, 523520, 109213, 141267]),\n",
       " array([0, 0, 1, 1, 1]),\n",
       " array([6.24151053, 6.24163567, 6.24172639, 6.24200721, 6.24232326]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remain_neighbors = n_neighbors[0][4493:4498]\n",
    "remain_neighbors, train_eval_labels[remain_neighbors], neigh_dists[0][4493:4498]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import clone\n",
    "\n",
    "\n",
    "train_mask = np.ones(train_eval_embeddings.shape[0], dtype=bool)\n",
    "train_mask[flip_list[7035]] = False\n",
    "reduced_embeddings = train_eval_embeddings[train_mask]\n",
    "reduced_labels = train_eval_labels[train_mask]\n",
    "old_pred = clf.predict(test_embeddings[7035].reshape(1, -1))[0]\n",
    "new_clf = clone(clf)\n",
    "new_clf.fit(reduced_embeddings, reduced_labels)\n",
    "new_pred = new_clf.predict(test_embeddings[7035].reshape(1, -1))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.24151053, 6.24163567, 6.24172639, 6.24200721, 6.24232326]]),\n",
       " array([[122723, 178963, 519331, 108361, 140136]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_clf.kneighbors(test_embeddings[7035].reshape(1, -1), return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4492]),)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(n_neighbors[0] == 298664)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MinimalSubsetToFlipPredictions.evaluate import retrain_and_evaluate_validity\n",
    "\n",
    "old_pred, new_pred, is_valid_subset = retrain_and_evaluate_validity(\n",
    "    clf=clf,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    x_test=test_embeddings[7035],\n",
    "    indices_to_exclude=flip_list[7035]\n",
    ")\n",
    "\n",
    "old_pred, new_pred, is_valid_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4493"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flip_list[7035])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9824"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.io import load_pickle\n",
    "import numpy as np\n",
    "\n",
    "l = load_pickle(\"esnli_deberta_large_yang_slow_baseline.pickle\")\n",
    "\n",
    "sums = [e is not None and len(e) > 0 for e in l]\n",
    "np.sum(np.array(sums))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrapperbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
