{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Approaches\n",
    "\n",
    "This notebook is intended to evaluate the subset approaches for esnli, where the\n",
    "output is a dataframe that looks something like:\n",
    "\n",
    "| Classifier | Approach              | Coverage (% identified) | Validity (% identified and leads to flip) | Median Size |\n",
    "|------------|-----------------------|--------------------------|--------------------------------------------|-------------|\n",
    "| Random     | Class Exclusion       | x                        | x                                          | x           |\n",
    "| Logistic   | Fast                  |                          |                                            |             |\n",
    "| Logistic   | Slow                  |                          |                                            |             |\n",
    "| Logistic   | Fast + CE fallback    |                          |                                            |             |\n",
    "| Logistic   | Slow + CE fallback    |                          |                                            |             |\n",
    "| KNN        | Greedy                |                          |                                            |             |\n",
    "| KNN        | Greedy + CE fallback  |                          |                                            |             |\n",
    "| SVM        | Greedy                |                          |                                            |             |\n",
    "| SVM        | Greedy + CE fallback  |                          |                                            |             |\n",
    "| DT         | Greedy                |                          |                                            |             |\n",
    "| DT         | Greedy + CE fallback  |                          |                                            |             |\n",
    "| LMeans     | Greedy                |                          |                                            |             |\n",
    "| LMeans     | Greedy + CE fallback  |                          |                                            |             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DATASET_NAME = \"esnli\"\n",
    "LABEL_SPACE = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "MODEL_NAME = \"deberta_large\"\n",
    "SEED = 42\n",
    "POOLER = \"mean_with_attention\"\n",
    "LAYER = 24\n",
    "\n",
    "# check of the non_empty sets, how many are actually valid \n",
    "def summarize_subset_results(flip_list: List[List[int]], is_valid: List[bool]):\n",
    "    total = len(flip_list)\n",
    "    valid = 0\n",
    "    identified_subset = 0\n",
    "    subset_sizes = []\n",
    "    for i, l in enumerate(flip_list):\n",
    "        if l is not None and len(l) > 0: \n",
    "            identified_subset += 1\n",
    "            if is_valid[i]:\n",
    "                valid += 1\n",
    "                subset_sizes.append(len(l))\n",
    "    metrics = {\n",
    "        \"Coverage\": round(identified_subset / total * 100, 2),\n",
    "        \"Validity\": round(valid / total * 100, 2),\n",
    "        \"Median Valid Subset Sizes\": np.median(np.array(subset_sizes))\n",
    "    }\n",
    "    print(f\"Identified {identified_subset}/{total} subsets\")\n",
    "    print(f\"{valid}/{identified_subset} identified subsets are valid\")\n",
    "    print(f\"Overall, validity is {valid}/{total}, or {metrics['Validity']}%\")\n",
    "    print(f\"Median Valid Subset Sizes is {metrics['Median Valid Subset Sizes']}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/samsoup/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samsoup/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Load Embeddings\n",
    "from utils.io import (\n",
    "    load_dataset_from_hf,\n",
    "    load_labels_at_split,\n",
    "    load_embeddings,\n",
    "    load_wrapperbox\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"train\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "eval_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"eval\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "test_embeddings = load_embeddings(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    split=\"test\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "train_eval_embeddings = np.vstack([train_embeddings, eval_embeddings])\n",
    "\n",
    "\n",
    "## Load Datasets and Labels\n",
    "dataset = load_dataset_from_hf(dataset=DATASET_NAME)\n",
    "train_labels = load_labels_at_split(dataset, \"train\")\n",
    "eval_labels = load_labels_at_split(dataset, \"eval\")\n",
    "train_eval_labels = np.concatenate([train_labels, eval_labels])\n",
    "test_labels = load_labels_at_split(dataset, \"test\")\n",
    "\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "train_eval_dataset = concatenate_datasets([dataset[\"train\"], dataset[\"eval\"]])\n",
    "dataset_dict = DatasetDict(\n",
    "    {\"train\": train_eval_dataset, \"test\": dataset[\"test\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samsoup/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 0 proposed subsets, only 0.0 is valid\n",
      "Validity: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Do metrics for Yang fast\n",
    "\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LogisticRegression\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "filename = \"esnli_deberta_large_yang2023_fast.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "ex_indices_to_check = np.arange(len(flip_list))\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = summarize_subset_results(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do metrics for Yang slow\n",
    "\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LogisticRegression\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "filename = \"esnli_deberta_large_yang2023_slow.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "ex_indices_to_check = np.arange(len(flip_list))\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = summarize_subset_results(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Do metrics for KNN\n",
    "\n",
    "import json\n",
    "import pprint\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"KNN\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "filename = f\"esnli_deberta_large_{wrapper_name}.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "total = len(flip_list)\n",
    "ex_indices_to_check = np.arange(total)\n",
    "flip_list = flip_list[:total]\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = summarize_subset_results(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "# Path to the output JSON file\n",
    "output_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{wrapper_name}_greedy_metrics.json'\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9824 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.470616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 558761, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score -1.097114\n",
      "[LightGBM] [Info] Start training from score -1.101229\n",
      "[LightGBM] [Info] Start training from score -1.097500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/9824 [00:16<2:05:12,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.408087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 558978, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score -1.096966\n",
      "[LightGBM] [Info] Start training from score -1.100971\n",
      "[LightGBM] [Info] Start training from score -1.097904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 67/9824 [00:31<1:11:51,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.371525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 558013, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score -1.097330\n",
      "[LightGBM] [Info] Start training from score -1.101106\n",
      "[LightGBM] [Info] Start training from score -1.097405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 92/9824 [00:47<1:23:33,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.462219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 558470, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score -1.097059\n",
      "[LightGBM] [Info] Start training from score -1.101580\n",
      "[LightGBM] [Info] Start training from score -1.097204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 217/9824 [01:03<37:36,  4.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.322925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 558947, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score -1.096321\n",
      "[LightGBM] [Info] Start training from score -1.100690\n",
      "[LightGBM] [Info] Start training from score -1.098831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 272/9824 [01:19<39:47,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.388774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 559202, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score -1.096777\n",
      "[LightGBM] [Info] Start training from score -1.100786\n",
      "[LightGBM] [Info] Start training from score -1.098278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 280/9824 [01:36<58:03,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.449948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 557606, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score -1.094048\n",
      "[LightGBM] [Info] Start training from score -1.101142\n",
      "[LightGBM] [Info] Start training from score -1.100662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 304/9824 [01:52<1:07:51,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.456064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 557377, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score -1.097189\n",
      "[LightGBM] [Info] Start training from score -1.103102\n",
      "[LightGBM] [Info] Start training from score -1.095562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 307/9824 [02:08<1:35:38,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.578366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 559200, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score -1.096785\n",
      "[LightGBM] [Info] Start training from score -1.100782\n",
      "[LightGBM] [Info] Start training from score -1.098274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 348/9824 [02:25<1:23:39,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.679754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 558931, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score -1.097053\n",
      "[LightGBM] [Info] Start training from score -1.100693\n",
      "[LightGBM] [Info] Start training from score -1.098094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 381/9824 [02:42<1:22:29,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.424240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261120\n",
      "[LightGBM] [Info] Number of data points in the train set: 558860, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score -1.096192\n",
      "[LightGBM] [Info] Start training from score -1.100959\n",
      "[LightGBM] [Info] Start training from score -1.098691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 391/9824 [03:10<1:16:33,  2.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m ex_indices_to_check \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(total)\n\u001b[1;32m     21\u001b[0m flip_list \u001b[38;5;241m=\u001b[39m flip_list[:total]\n\u001b[0;32m---> 23\u001b[0m is_valid \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_predictions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflip_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflip_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_eval_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_eval_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mex_indices_to_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_indices_to_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m metrics \u001b[38;5;241m=\u001b[39m summarize_subset_results(\n\u001b[1;32m     33\u001b[0m     flip_list\u001b[38;5;241m=\u001b[39mflip_list,\n\u001b[1;32m     34\u001b[0m     is_valid\u001b[38;5;241m=\u001b[39mis_valid\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m metrics, is_valid[:\u001b[38;5;241m10\u001b[39m]\n",
      "File \u001b[0;32m~/Work/WrapperBox/MinimalSubsetToFlipPredictions/evaluate.py:42\u001b[0m, in \u001b[0;36mevaluate_predictions\u001b[0;34m(clf, flip_list, train_embeddings, train_labels, test_embeddings, ex_indices_to_check)\u001b[0m\n\u001b[1;32m     40\u001b[0m         is_valid_subsets\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     _, _, is_valid_subset \u001b[38;5;241m=\u001b[39m \u001b[43mretrain_and_evaluate_validity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_ex_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices_to_exclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     is_valid_subsets\u001b[38;5;241m.\u001b[39mappend(is_valid_subset)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_valid_subsets\n",
      "File \u001b[0;32m~/Work/WrapperBox/MinimalSubsetToFlipPredictions/evaluate.py:21\u001b[0m, in \u001b[0;36mretrain_and_evaluate_validity\u001b[0;34m(clf, train_embeddings, train_labels, x_test, indices_to_exclude)\u001b[0m\n\u001b[1;32m     19\u001b[0m old_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(x_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m new_clf \u001b[38;5;241m=\u001b[39m clone(clf)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mnew_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduced_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduced_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m new_pred \u001b[38;5;241m=\u001b[39m new_clf\u001b[38;5;241m.\u001b[39mpredict(x_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# this subset is valid only if new prediction does not equal old prediction\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/lightgbm/sklearn.py:885\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    882\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    883\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m~/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/lightgbm/engine.py:255\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    257\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/lightgbm/basic.py:3433\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3426\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[1;32m   3427\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[1;32m   3428\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3429\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[1;32m   3430\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3431\u001b[0m     )\n\u001b[1;32m   3432\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[0;32m-> 3433\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3434\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[1;32m   3435\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[0;32m~/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/lightgbm/basic.py:2462\u001b[0m, in \u001b[0;36mDataset.construct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2455\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[1;32m   2456\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[1;32m   2457\u001b[0m                 data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m   2458\u001b[0m                 used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[1;32m   2459\u001b[0m             )\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2461\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[0;32m-> 2462\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2463\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2464\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2465\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[1;32m   2468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/lightgbm/basic.py:2079\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[1;32m   2077\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_csc(data, params_str, ref_dataset)\n\u001b[1;32m   2078\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m-> 2079\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__init_from_np2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_pyarrow_table(data):\n\u001b[1;32m   2081\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_pyarrow_table(data, params_str, ref_dataset)\n",
      "File \u001b[0;32m~/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/lightgbm/basic.py:2218\u001b[0m, in \u001b[0;36mDataset.__init_from_np2d\u001b[0;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(mat\u001b[38;5;241m.\u001b[39mreshape(mat\u001b[38;5;241m.\u001b[39msize), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m   2217\u001b[0m ptr_data, type_ptr_data, _ \u001b[38;5;241m=\u001b[39m _c_float_array(data)\n\u001b[0;32m-> 2218\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_DatasetCreateFromMat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_ptr_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_C_API_IS_ROW_MAJOR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Do metrics for LGBM\n",
    "\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LGBM\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "filename = f\"esnli_deberta_large_{wrapper_name}.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "total = len(flip_list)\n",
    "ex_indices_to_check = np.arange(total)\n",
    "flip_list = flip_list[:total]\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = summarize_subset_results(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "# Path to the output JSON file\n",
    "output_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{wrapper_name}_greedy_metrics.json'\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'esnli_deberta_large_LMeans.part_1.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pickle\n\u001b[1;32m      6\u001b[0m wrapper_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLMeans\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m flip_list \u001b[38;5;241m=\u001b[39m \u001b[43mload_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATASET_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mwrapper_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.part_1.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m is_valid \u001b[38;5;241m=\u001b[39m evaluate_predictions(\n\u001b[1;32m     10\u001b[0m     clf\u001b[38;5;241m=\u001b[39mknn_clf,\n\u001b[1;32m     11\u001b[0m     flip_list\u001b[38;5;241m=\u001b[39mflip_list,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     ex_indices_to_check\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(test_labels\u001b[38;5;241m.\u001b[39msize),\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# check of the non_empty sets, how many are actually valid \u001b[39;00m\n",
      "File \u001b[0;32m~/Work/WrapperBox/utils/io.py:31\u001b[0m, in \u001b[0;36mload_pickle\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_pickle\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m     32\u001b[0m         data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'esnli_deberta_large_LMeans.part_1.pickle'"
     ]
    }
   ],
   "source": [
    "## Do metrics for LMeans\n",
    "\n",
    "from MinimalSubsetToFlipPredictions.evaluate import evaluate_predictions\n",
    "import pickle\n",
    "\n",
    "wrapper_name = \"LMeans\"\n",
    "clf = load_wrapperbox(\n",
    "    dataset=DATASET_NAME,\n",
    "    model=MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    pooler=POOLER,\n",
    "    wrapperbox=wrapper_name\n",
    ")\n",
    "\n",
    "filename = f\"esnli_deberta_large_{wrapper_name}.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    flip_list = pickle.load(handle)\n",
    "\n",
    "total = len(flip_list)\n",
    "ex_indices_to_check = np.arange(total)\n",
    "flip_list = flip_list[:total]\n",
    "\n",
    "is_valid = evaluate_predictions(\n",
    "    clf=clf,\n",
    "    flip_list=flip_list,\n",
    "    train_embeddings=train_eval_embeddings,\n",
    "    train_labels=train_eval_labels,\n",
    "    test_embeddings=test_embeddings,\n",
    "    ex_indices_to_check=ex_indices_to_check,\n",
    ")\n",
    "\n",
    "metrics = summarize_subset_results(\n",
    "    flip_list=flip_list,\n",
    "    is_valid=is_valid\n",
    ")\n",
    "\n",
    "pprint(metrics)\n",
    "\n",
    "# Path to the output JSON file\n",
    "output_file_path = f'{DATASET_NAME}_{MODEL_NAME}_{wrapper_name}_greedy_metrics.json'\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrapperbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
