{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook investigates a simple idea for valid subsets that leads to \n",
    "prediction flip, by simply just removing all candidate example-based\n",
    "explanations (examples used in inference), and note how many times it is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants for control\n",
    "\n",
    "DATASET = \"esnli\"\n",
    "MODEL = \"deberta-large\"\n",
    "SEED = 42\n",
    "POOLER = \"mean_with_attention\"\n",
    "LAYER = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/samsoup/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "## Load Data\n",
    "# load embeddings\n",
    "from data.embeddings import load_saved_embeddings\n",
    "train_embeddings = load_saved_embeddings(\n",
    "    dataset=DATASET,\n",
    "    model=MODEL,\n",
    "    seed=SEED,\n",
    "    split=\"train\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "eval_embeddings = load_saved_embeddings(\n",
    "    dataset=DATASET,\n",
    "    model=MODEL,\n",
    "    seed=SEED,\n",
    "    split=\"eval\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "test_embeddings = load_saved_embeddings(\n",
    "    dataset=DATASET,\n",
    "    model=MODEL,\n",
    "    seed=SEED,\n",
    "    split=\"test\",\n",
    "    pooler=POOLER,\n",
    "    layer=LAYER\n",
    ")\n",
    "\n",
    "# load labels \n",
    "from data.datasets import load_dataset_from_hf, load_labels_at_split\n",
    "import numpy as np\n",
    "dataset = load_dataset_from_hf(dataset=DATASET)\n",
    "train_labels = load_labels_at_split(dataset, \"train\")\n",
    "eval_labels = load_labels_at_split(dataset, \"eval\")\n",
    "train_eval_embeddings = np.vstack([train_embeddings, eval_embeddings])\n",
    "train_eval_labels = np.concatenate([train_labels, eval_labels])\n",
    "test_labels = load_labels_at_split(dataset, \"test\")\n",
    "\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "train_eval_dataset = concatenate_datasets([dataset[\"train\"], dataset[\"eval\"]])\n",
    "dataset_dict = DatasetDict(\n",
    "    {\"train\": train_eval_dataset, \"test\": dataset[\"test\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samsoup/anaconda3/envs/wrapperbox/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.1.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# KNN: how many times is the K neighbors a valid subset?\n",
    "from data.models import load_saved_wrapperbox_model\n",
    "from utils.inference import find_majority_batched\n",
    "\n",
    "knn_clf = load_saved_wrapperbox_model(\n",
    "    dataset=\"esnli\",\n",
    "    model=\"deberta-large\",\n",
    "    seed=42,\n",
    "    pooler=\"mean_with_attention\",\n",
    "    wrapperbox=\"KNN\"\n",
    ")\n",
    "\n",
    "K = knn_clf.n_neighbors\n",
    "\n",
    "predictions = knn_clf.predict(test_embeddings)\n",
    "neigh_indices = knn_clf.kneighbors(\n",
    "    X=test_embeddings,\n",
    "    n_neighbors=len(train_eval_labels),\n",
    "    return_distance=False,\n",
    ")\n",
    "neigh_labels = train_eval_labels[neigh_indices]\n",
    "# remove the K neighbors is the same as sliding the window down by K \n",
    "# and check the majority of the next K, to see if prediction has flipped\n",
    "next_window = neigh_labels[:, K : 2*K]\n",
    "majority_current = find_majority_batched(next_window)\n",
    "changed_majority = np.logical_not(majority_current == predictions)\n",
    "num_changed = np.sum(changed_majority)\n",
    "\n",
    "# Print a summary of changed_majority\n",
    "print(f\"{num_changed} of {train_eval_labels.size} has changed prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrapperbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
